{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dace61c-552c-40e9-be0d-26d251052c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gradient_ascent_functions import * # the gradient ascent functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59343f1b-f13e-4a61-a368-8084efc86903",
   "metadata": {},
   "source": [
    "## Processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cf72c-4bac-465d-9522-c5ea04a9e701",
   "metadata": {},
   "source": [
    "The values of `Sex` and `Embarked` (port of embarkation) are transformed into integeres with the following correspondence:\n",
    "- Sex:\n",
    "    - `male` -> `0`\n",
    "    - `female` -> `1`\n",
    "- Embarked:\n",
    "    - `C` -> `-1`\n",
    "    - `Q` -> `0`\n",
    "    - `S` -> `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5271a0-4f7d-45fb-880d-b59a23bdb6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076277</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0         0       3    0 -0.096239      1      0 -0.048707         1\n",
       "1         1       1    1  0.103761      1      0  0.076277        -1\n",
       "2         1       3    1 -0.046239      0      0 -0.047390         1\n",
       "3         1       1    1  0.066261      1      0  0.040786         1\n",
       "4         0       3    0  0.066261      0      0 -0.047146         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data and dropping features uncorrelated with survival outcome\n",
    "titanic_dataset = pd.read_csv(\"train.csv\")\n",
    "training_dataset = titanic_dataset.drop(columns=[\"Ticket\", 'Cabin', 'Name', 'PassengerId'])\n",
    "\n",
    "#Normalizing with the mean the Age and Fare values\n",
    "training_dataset['Age'] = ((training_dataset['Age'] - training_dataset['Age'].mean()) / training_dataset['Age'].max())\n",
    "training_dataset['Fare'] = ((training_dataset['Fare'] - training_dataset['Fare'].mean()) / training_dataset['Fare'].max())\n",
    "\n",
    "# Droppig passangers with missing values\n",
    "training_dataset = training_dataset.dropna(subset=[\"Embarked\", \"Age\"])\n",
    "\n",
    "# Discretizing the `Sex` and `Embarked` values\n",
    "training_dataset['Sex'] = training_dataset['Sex'].replace(to_replace=[\"male\", \"female\"], value=[0, 1])\n",
    "training_dataset['Embarked'] = training_dataset['Embarked'].replace(to_replace=[\"C\", \"Q\", \"S\"], value=[-1, 0, 1])\n",
    "\n",
    "# Transforming the dataset in numpy arrays to implement the gradient ascent\n",
    "data_matrix = training_dataset.drop(columns='Survived').to_numpy()\n",
    "target_array = training_dataset['Survived'].to_numpy().reshape((-1, 1))\n",
    "\n",
    "# adding a column on ones for to the data matrix corresponding to the coventional x0 feture\n",
    "column_of_ones = np.ones(shape=(data_matrix.shape[0], 1))\n",
    "data_matrix = np.hstack((column_of_ones, data_matrix))\n",
    "\n",
    "# Visualizing the first elements of the training_dataset\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664e4cf3-e94c-4966-b685-421d772b9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Function to compute the sigmoid of a given input x.\n",
    "    \n",
    "    Input:\n",
    "    x: it's the input data matrix. The shape is (N, H)\n",
    "\n",
    "    Output:\n",
    "    g: The sigmoid of the input x\n",
    "    '''\n",
    "    g = 1 / (1 + np.exp(-x))\n",
    "    return g\n",
    "\n",
    "def log_likelihood(theta,features,target):\n",
    "    '''\n",
    "    Function to compute the log likehood of theta according to data x and label y\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix.\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    target: the label array\n",
    "    \n",
    "    Output:\n",
    "    log_g: the log likehood of theta according to data x and label y\n",
    "    '''\n",
    "      \n",
    "    log_l=((target * np.log(sigmoid(features @ theta))+(1-target)*np.log(1-sigmoid(features @ theta))).sum()) / len(features)\n",
    "\n",
    "    return log_l\n",
    "\n",
    "\n",
    "def predictions(features, theta):\n",
    "    '''\n",
    "    Function to compute the predictions for the input features\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix.\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    \n",
    "    Output:\n",
    "    preds: the predictions of the input features\n",
    "    '''\n",
    "      \n",
    "    response=sigmoid(features @ theta)\n",
    "    preds = np.where(response >=0.5, 1, 0)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def update_theta(theta, target, preds, features, lr):\n",
    "    '''\n",
    "    Function to compute the gradient of the log likelihood\n",
    "    and then return the updated weights\n",
    "\n",
    "    Input:\n",
    "    theta: the model parameter matrix.\n",
    "    target: the label array\n",
    "    preds: the predictions of the input features\n",
    "    features: it's the input data matrix. The shape is (N, H)\n",
    "    lr: the learning rate\n",
    "    \n",
    "    Output:\n",
    "    theta: the updated model parameter matrix.\n",
    "    '''\n",
    "    \n",
    "    # (712, 1) @ (712, 8)\n",
    "    log_lik_deriv = (((target - sigmoid(features @ theta)).transpose() @ features).transpose() / len(features))\n",
    "    theta = theta + lr * log_lik_deriv\n",
    "    return theta \n",
    "\n",
    "def gradient_ascent(theta, features, target, lr, num_steps):\n",
    "    '''\n",
    "    Function to execute the gradient ascent algorithm\n",
    "\n",
    "    Input:\n",
    "    theta: the model parameter matrix.\n",
    "    target: the label array\n",
    "    num_steps: the number of iterations \n",
    "    features: the input data matrix. The shape is (N, H)\n",
    "    lr: the learning rate\n",
    "    \n",
    "    Output:\n",
    "    theta: the final model parameter matrix.\n",
    "    log_likelihood_history: the values of the log likelihood during the process\n",
    "    '''\n",
    "\n",
    "    log_likelihood_history = np.zeros(num_steps)\n",
    "    \n",
    "    \n",
    "    for step in range(num_steps):\n",
    "      \n",
    "        log_likelihood_history[step]=log_likelihood(theta,features,target)\n",
    "        preds=predictions(features, theta)\n",
    "        theta=update_theta(theta, target, preds, features, lr)\n",
    "    \n",
    "    return theta, log_likelihood_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1a0e7-67bf-4a1a-86f8-cb5c995d28b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementing the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f82aeb3-c197-40d3-bf32-6ed595b5f282",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pc03eNeqrhkT",
    "outputId": "b89c6414-92d7-4052-b686-d33f1c54d697"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2377/3886130686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run Gradient Ascent method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtheta_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_l_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plotting the log likelihood over iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FDS/gradient_ascent_functions.py\u001b[0m in \u001b[0;36mgradient_ascent\u001b[0;34m(theta, features, target, lr, num_steps)\u001b[0m\n\u001b[1;32m     84\u001b[0m     '''\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mlog_likelihood_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize theta0\n",
    "theta0 = np.zeros((data_matrix.shape[1], 1)) # 1dimensional verical array of shape (8, 1) \n",
    "\n",
    "# Run Gradient Ascent method\n",
    "n_iter=2000\n",
    "theta_final, log_l_history = gradient_ascent(theta0, data_matrix, target_array, lr=.05 , num_steps=n_iter)\n",
    "\n",
    "# Plotting the log likelihood over iterations\n",
    "fig,ax = plt.subplots(num=2)\n",
    "ax.set_ylabel('l(Theta)')\n",
    "ax.set_xlabel('Iterations')\n",
    "_=ax.plot(range(len(log_l_history)),log_l_history,'b.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
